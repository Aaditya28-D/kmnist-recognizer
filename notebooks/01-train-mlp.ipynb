{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8c4e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "780bbc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using repo root: /Users/aaditya/Workspace/Learning/Github/projects/kmnist-recognizer\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Find repo root (folder containing `src`)\n",
    "REPO_ROOT = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().parent\n",
    "sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "print(\"Using repo root:\", REPO_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4678e3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using repo root: /Users/aaditya/Workspace/Learning/Github/projects/kmnist-recognizer\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Walk up until we find a folder that contains 'src'\n",
    "here = Path.cwd()\n",
    "REPO_ROOT = None\n",
    "for c in [here, *here.parents]:\n",
    "    if (c / \"src\").is_dir():\n",
    "        REPO_ROOT = c\n",
    "        break\n",
    "\n",
    "if REPO_ROOT is None:\n",
    "    raise RuntimeError(\"Couldn't find project root (folder containing 'src').\")\n",
    "\n",
    "# Make 'src' importable\n",
    "sys.path.insert(0, str(REPO_ROOT / \"src\"))\n",
    "print(\"Using repo root:\", REPO_ROOT)\n",
    "\n",
    "DATA_DIR   = REPO_ROOT / \"data\"\n",
    "MODELS_DIR = REPO_ROOT / \"models\"\n",
    "\n",
    "import numpy as np\n",
    "from src.kmnist.models.mlp import MLPWide\n",
    "from src.kmnist.train import train_model, pick_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5eb99da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expect these four files in data/\n",
    "x_train = np.load(DATA_DIR / \"kmnist-train-imgs.npz\")[\"arr_0\"]  # (60000, 28, 28)\n",
    "y_train = np.load(DATA_DIR / \"kmnist-train-labels.npz\")[\"arr_0\"]  # (60000,)\n",
    "x_test  = np.load(DATA_DIR / \"kmnist-test-imgs.npz\")[\"arr_0\"]     # (10000, 28, 28)\n",
    "y_test  = np.load(DATA_DIR / \"kmnist-test-labels.npz\")[\"arr_0\"]   # (10000,)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39cb58b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset  # <-- missing import\n",
    "\n",
    "class KMNISTArrayDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wrap numpy arrays (H,W) uint8 -> torch tensors [1,28,28] float in [0,1].\n",
    "    KMNIST already uses dark background / light foreground, so no inversion here.\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img = torch.from_numpy(self.x[i]).float() / 255.0  # [28,28] -> [0,1]\n",
    "        img = img.unsqueeze(0)                             # [1,28,28]\n",
    "        label = int(self.y[i])\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0b142b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 5000, 10000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_ds = KMNISTArrayDataset(x_train, y_train)\n",
    "test_ds       = KMNISTArrayDataset(x_test,  y_test)\n",
    "\n",
    "# 55k train / 5k val split (deterministic)\n",
    "val_size = 5000\n",
    "train_size = len(full_train_ds) - val_size\n",
    "train_ds, val_ds = random_split(\n",
    "    full_train_ds,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b17c992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n",
      "Epoch 01 | train acc 0.864 loss 0.449 | val acc 0.929 loss 0.228\n",
      "Epoch 02 | train acc 0.926 loss 0.241 | val acc 0.944 loss 0.185\n",
      "Epoch 03 | train acc 0.944 loss 0.183 | val acc 0.954 loss 0.153\n",
      "Epoch 04 | train acc 0.954 loss 0.150 | val acc 0.958 loss 0.141\n",
      "Epoch 05 | train acc 0.961 loss 0.124 | val acc 0.963 loss 0.121\n",
      "Epoch 06 | train acc 0.968 loss 0.105 | val acc 0.962 loss 0.127\n",
      "Epoch 07 | train acc 0.971 loss 0.091 | val acc 0.964 loss 0.125\n",
      "Epoch 08 | train acc 0.973 loss 0.086 | val acc 0.964 loss 0.127\n",
      "Epoch 09 | train acc 0.976 loss 0.074 | val acc 0.966 loss 0.118\n",
      "Epoch 10 | train acc 0.978 loss 0.068 | val acc 0.967 loss 0.118\n",
      "Epoch 11 | train acc 0.980 loss 0.063 | val acc 0.967 loss 0.117\n",
      "Epoch 12 | train acc 0.981 loss 0.058 | val acc 0.968 loss 0.112\n",
      "Epoch 13 | train acc 0.982 loss 0.055 | val acc 0.967 loss 0.120\n",
      "Epoch 14 | train acc 0.983 loss 0.051 | val acc 0.968 loss 0.112\n",
      "Epoch 15 | train acc 0.985 loss 0.047 | val acc 0.971 loss 0.117\n",
      "Epoch 16 | train acc 0.984 loss 0.046 | val acc 0.969 loss 0.120\n",
      "Epoch 17 | train acc 0.986 loss 0.042 | val acc 0.968 loss 0.122\n",
      "Epoch 18 | train acc 0.988 loss 0.039 | val acc 0.969 loss 0.118\n",
      "Epoch 19 | train acc 0.988 loss 0.038 | val acc 0.971 loss 0.109\n",
      "Epoch 20 | train acc 0.988 loss 0.036 | val acc 0.969 loss 0.123\n",
      "Epoch 21 | train acc 0.988 loss 0.035 | val acc 0.970 loss 0.120\n",
      "Epoch 22 | train acc 0.988 loss 0.034 | val acc 0.969 loss 0.120\n",
      "Epoch 23 | train acc 0.990 loss 0.032 | val acc 0.973 loss 0.119\n",
      "Epoch 24 | train acc 0.990 loss 0.031 | val acc 0.971 loss 0.127\n",
      "Epoch 25 | train acc 0.989 loss 0.033 | val acc 0.970 loss 0.127\n",
      "Epoch 26 | train acc 0.991 loss 0.029 | val acc 0.970 loss 0.127\n",
      "Epoch 27 | train acc 0.990 loss 0.031 | val acc 0.971 loss 0.120\n",
      "Epoch 28 | train acc 0.991 loss 0.029 | val acc 0.970 loss 0.125\n",
      "Epoch 29 | train acc 0.991 loss 0.026 | val acc 0.970 loss 0.131\n",
      "Epoch 30 | train acc 0.992 loss 0.025 | val acc 0.971 loss 0.132\n",
      "Epoch 31 | train acc 0.992 loss 0.025 | val acc 0.970 loss 0.128\n",
      "Epoch 32 | train acc 0.992 loss 0.024 | val acc 0.969 loss 0.128\n",
      "Epoch 33 | train acc 0.991 loss 0.026 | val acc 0.971 loss 0.129\n",
      "Epoch 34 | train acc 0.992 loss 0.023 | val acc 0.970 loss 0.132\n",
      "Epoch 35 | train acc 0.992 loss 0.024 | val acc 0.970 loss 0.124\n",
      "Epoch 36 | train acc 0.992 loss 0.024 | val acc 0.974 loss 0.126\n",
      "Epoch 37 | train acc 0.993 loss 0.021 | val acc 0.970 loss 0.131\n",
      "Epoch 38 | train acc 0.992 loss 0.024 | val acc 0.973 loss 0.119\n",
      "Epoch 39 | train acc 0.992 loss 0.022 | val acc 0.972 loss 0.122\n",
      "Epoch 40 | train acc 0.993 loss 0.020 | val acc 0.970 loss 0.130\n",
      "Saved weights -> /Users/aaditya/Workspace/Learning/Github/projects/kmnist-recognizer/models/mlp_model_v003.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': 0.020123697447979993, 'train_acc': 0.9932363636363636}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = pick_device()\n",
    "print(\"device:\", device)\n",
    "\n",
    "model = MLPWide(p=0.35)\n",
    "\n",
    "EPOCHS = 40\n",
    "LR     = 3e-3\n",
    "\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    epochs=EPOCHS,\n",
    "    lr=LR,\n",
    "    val_loader=val_loader,  # optional; will print val metrics\n",
    "    out_dir=MODELS_DIR,     # <-- only this, no best.pt, no early stopping logic\n",
    "    prefix=\"mlp_model\"      # filenames: mlp_model_v001.pt, v002, ...\n",
    ")\n",
    "\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e851fcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.3702347909927368, 'acc': 0.9276}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, loader: DataLoader, device: torch.device):\n",
    "    model.eval().to(device)\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb)\n",
    "        loss_sum += criterion(logits, yb).item() * xb.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        total   += xb.size(0)\n",
    "    return {\"loss\": loss_sum/total, \"acc\": correct/total}\n",
    "\n",
    "test_metrics = evaluate(model, test_loader, device)\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d36db36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/aaditya/Workspace/Learning/Github/projects/kmnist-recognizer/models/mlp_model_v001.pt',\n",
       " '/Users/aaditya/Workspace/Learning/Github/projects/kmnist-recognizer/models/mlp_model_v002.pt',\n",
       " '/Users/aaditya/Workspace/Learning/Github/projects/kmnist-recognizer/models/mlp_model_v003.pt']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "saved = sorted(glob(str(MODELS_DIR / \"mlp_model_v*.pt\")))\n",
    "saved[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db07d9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /Users/aaditya/Workspace/Learning/Github/projects/kmnist-recognizer/models/mlp_model_v003.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.3702347909927368, 'acc': 0.9276}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the last saved version and evaluate\n",
    "last_path = sorted(glob(str(MODELS_DIR / \"mlp_model_v*.pt\")))[-1]\n",
    "print(\"Loading:\", last_path)\n",
    "\n",
    "reloaded = MLPWide(p=0.35)\n",
    "reloaded.load_state_dict(torch.load(last_path, map_location=\"cpu\"))\n",
    "reloaded_metrics = evaluate(reloaded, test_loader, device)\n",
    "reloaded_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7cb729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
